{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1113116",
   "metadata": {},
   "source": [
    "# Project 3: Reddit Post Sorting\n",
    "\n",
    "- **ExplainLikeImFive (ELI5)** - Explain Like I'm Five is the best forum and archive on the internet for layperson-friendly explanations. Don't Panic!\n",
    "- **AskScience** - Ask a science question, get a science answer.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "We will be analyzing a random collection of posts from two subReddits, **ExplainLikeImFive** and **AskScience**, in order to build a model to predict if an individual posts belong to ELI5 or AskScience; we will be analyzing the Title and Body of the Post.\n",
    "\n",
    "**What am I hoping to achieve with this?**\n",
    "> If ELI5 is distinguishable from AskScience.\n",
    "\n",
    "**Why?**\n",
    "> To see if a subreddit focused on explaining things in a simple manner is that much different than a subreddit that wants to explain it any way they can."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6411d5",
   "metadata": {},
   "source": [
    "# Modeling and Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daabf7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb596c1",
   "metadata": {},
   "source": [
    "## Read in Data\n",
    "\n",
    "We also will remove the null values again, as we found was best during our EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eb00b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_df = pd.read_csv('../data/ex_df.csv')\n",
    "ex_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d53ac274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ask_df = pd.read_csv('../data/ask_df.csv')\n",
    "ask_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "028d7de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_df['combo'] = ex_df['title'] + ' ' + ex_df['selftext']\n",
    "ask_df['combo'] = ask_df['title'] + ' ' + ask_df['selftext']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1730f3a5",
   "metadata": {},
   "source": [
    "Now lets combine our dataframes into a single dataframe for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec816e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "culmination = pd.concat([ex_df, ask_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b33e5a",
   "metadata": {},
   "source": [
    "## Model Setup\n",
    "\n",
    "First let's set our stopwords list obtained from our EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55d9a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = culmination['combo']\n",
    "y = culmination['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad2e2e",
   "metadata": {},
   "source": [
    "### Null Model\n",
    "It's important to know what our baseline success rate would be without a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31752ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "askscience           0.571501\n",
       "explainlikeimfive    0.428499\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfde941",
   "metadata": {},
   "source": [
    "**Null Model Analysis**\n",
    "> Our null model, flatly predicting the more common class, would be 56.15% accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c179e99d",
   "metadata": {},
   "source": [
    "### Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f015708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be971666",
   "metadata": {},
   "source": [
    "### Stop Word Adjustments\n",
    "\n",
    "From our EDA, we know a list of words we want removed in additional to the default list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa5fff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to use the standard stopwords\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "#We also want to remove the ELI5, otherwise it would be a (nearly) 100% indicator\n",
    "en_stopwords.append('eli5')\n",
    "\n",
    "#From our analysis we also found some other words that would be beneficial to remove\n",
    "en_stopwords.append('https')\n",
    "en_stopwords.append('www')\n",
    "en_stopwords.append('like')\n",
    "en_stopwords.append('would')\n",
    "en_stopwords.append('imgur')\n",
    "en_stopwords.append('com')\n",
    "en_stopwords.append('en')\n",
    "en_stopwords.append('wikipedia')\n",
    "en_stopwords.append('org')\n",
    "en_stopwords.append('wiki')\n",
    "en_stopwords.append('x200b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec16eba",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "We want to try a few models to gauge a reasonable success rate in relation to our null model as well as a way to reference each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3adf6d",
   "metadata": {},
   "source": [
    "# Model 1: Count Vectorizer and Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8428f2f4",
   "metadata": {},
   "source": [
    "**Let's set a pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e766733",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = en_stopwords)),\n",
    "    ('forest', RandomForestClassifier())    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2df1c3",
   "metadata": {},
   "source": [
    "**Now we pass in the parameters we want to gridsearch over.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e05440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add our hyperparameters\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [150_000],\n",
    "    'cvec__min_df': [3],\n",
    "    'cvec__max_df': [.55],\n",
    "    'cvec__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "    'forest__n_estimators': [50],\n",
    "    'forest__max_depth': [100],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba316e5",
   "metadata": {},
   "source": [
    "**We initialize our GridSearch for our model selection.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97664e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "gs = GridSearchCV(\n",
    "    # what object are we optimizing?\n",
    "    estimator = pipe,\n",
    "    \n",
    "    # what parameters values are we searching?\n",
    "    param_grid = pipe_params,\n",
    "    \n",
    "    # 5-fold cross-validation.\n",
    "    cv = 5,\n",
    "    \n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a54441",
   "metadata": {},
   "source": [
    "**Finally, we fit our model to our training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c5c6d6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    \"you're\",\n",
       "                                                                    \"you've\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it',\n",
       "                                                                    \"it's\",\n",
       "                                                                    'its',\n",
       "                                                                    'itself', ...])),\n",
       "                                       ('forest', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.55], 'cvec__max_features': [150000],\n",
       "                         'cvec__min_df': [3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
       "                         'forest__max_depth': [100],\n",
       "                         'forest__n_estimators': [50]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a900cccc",
   "metadata": {},
   "source": [
    "Then analyze what the GridSearch chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ec27c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.55,\n",
       " 'cvec__max_features': 150000,\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'forest__max_depth': 100,\n",
       " 'forest__n_estimators': 50}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the best hyperparameters?\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d002047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9764233759719088"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on training set.\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6bcace2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7525458248472505"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on testing set.\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35417d0",
   "metadata": {},
   "source": [
    "# Model 2: TfidfVectorizer and Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1db1a9",
   "metadata": {},
   "source": [
    "**Let's set a pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4c0fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Pipeline([\n",
    "    ('cvec', TfidfVectorizer(stop_words = en_stopwords)),\n",
    "    ('forest', RandomForestClassifier())    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebcd2d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add our hyperparameters\n",
    "pipe_params2 = {\n",
    "    'cvec__max_features': [150_000],\n",
    "    'cvec__min_df': [3],\n",
    "    'cvec__max_df': [.55],\n",
    "    'cvec__ngram_range': [(1,2)],\n",
    "    'forest__n_estimators': [50],\n",
    "    'forest__max_depth': [100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b1aef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "gs2 = GridSearchCV(\n",
    "    # what object are we optimizing?\n",
    "    estimator = pipe2,\n",
    "    \n",
    "    # what parameters values are we searching?\n",
    "    param_grid = pipe_params2,\n",
    "    \n",
    "    # 5-fold cross-validation.\n",
    "    cv = 5,\n",
    "    \n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5704ba6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec',\n",
       "                                        TfidfVectorizer(stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    \"you're\",\n",
       "                                                                    \"you've\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it',\n",
       "                                                                    \"it's\",\n",
       "                                                                    'its',\n",
       "                                                                    'itself', ...])),\n",
       "                                       ('forest', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.55], 'cvec__max_features': [150000],\n",
       "                         'cvec__min_df': [3], 'cvec__ngram_range': [(1, 2)],\n",
       "                         'forest__max_depth': [100],\n",
       "                         'forest__n_estimators': [50]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f4e2876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.55,\n",
       " 'cvec__max_features': 150000,\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'forest__max_depth': 100,\n",
       " 'forest__n_estimators': 50}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the best hyperparameters?\n",
    "gs2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6442bedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9937296212691247"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on training set.\n",
    "gs2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0a2f319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7563645621181263"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on testing set.\n",
    "gs2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fe1bf2",
   "metadata": {},
   "source": [
    "# Model 3: TfidfVectorizer and KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b26323",
   "metadata": {},
   "source": [
    "**Let's set a pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef12e4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe3 = Pipeline([\n",
    "    ('cvec', TfidfVectorizer(stop_words = en_stopwords)),\n",
    "    ('knn', KNeighborsClassifier())    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11bd8432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add our hyperparameters\n",
    "pipe_params3 = {\n",
    "    'cvec__max_features': [100_000],\n",
    "    'cvec__min_df': [3],\n",
    "    'cvec__max_df': [.9],\n",
    "    'cvec__ngram_range': [(1,2)],\n",
    "    'knn__n_neighbors': [4],\n",
    "    'knn__p':  [2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33707713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "gs3 = GridSearchCV(\n",
    "    # what object are we optimizing?\n",
    "    estimator = pipe3,\n",
    "    \n",
    "    # what parameters values are we searching?\n",
    "    param_grid = pipe_params3,\n",
    "    \n",
    "    # 5-fold cross-validation.\n",
    "    cv = 5,\n",
    "    \n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1283bb1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec',\n",
       "                                        TfidfVectorizer(stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    \"you're\",\n",
       "                                                                    \"you've\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it',\n",
       "                                                                    \"it's\",\n",
       "                                                                    'its',\n",
       "                                                                    'itself', ...])),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.9], 'cvec__max_features': [100000],\n",
       "                         'cvec__min_df': [3], 'cvec__ngram_range': [(1, 2)],\n",
       "                         'knn__n_neighbors': [4], 'knn__p': [2]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "faa78488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 100000,\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'knn__n_neighbors': 4,\n",
       " 'knn__p': 2}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the best hyperparameters?\n",
    "gs3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d6d39c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.800351141208929"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on training set.\n",
    "gs3.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f1d5578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6975560081466395"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on testing set.\n",
    "gs3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7879d7",
   "metadata": {},
   "source": [
    "## Null Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e958b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "askscience           0.571501\n",
       "explainlikeimfive    0.428499\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed81bbf",
   "metadata": {},
   "source": [
    "---\n",
    "# Overall Modeling Analysis\n",
    "Our 3 models have varying, though similar, levels of accuracy on train and test. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f218c0c9",
   "metadata": {},
   "source": [
    "### Model 1 Analysis:\n",
    "> Model 1 used CountVector and RandomForestClassifier\n",
    "\n",
    "- Training set accuracy of 97.6%\n",
    "- Testing set accuracy of 75.2%\n",
    "\n",
    "Our data is likely very overfit with such a high train and test accuracy difference. However, 75% is high enough for us to use. This data tells us there is possibly a discernable difference between the subreddits.\n",
    "\n",
    "> - **Best Hyperparameters**:\n",
    "> - 'cvec__max_df': 0.55,\n",
    "> - 'cvec__max_features': 150000,\n",
    "> - 'cvec__min_df': 3,\n",
    "> - 'cvec__ngram_range': (1, 1),\n",
    "> - 'forest__max_depth': 100,\n",
    "> - 'forest__n_estimators': 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c037e2e",
   "metadata": {},
   "source": [
    "### Model 2 Analysis:\n",
    "> Model 2 used TfidVectorizer and RandomForestClassifier\n",
    "\n",
    "- Training set accuracy of 99.4%\n",
    "- Testing set accuracy of 75.6%\n",
    "\n",
    "Our data is likely very overfit with such a high train and test accuracy difference. However, 75% is high enough for us to use. This data tells us there is possibly a discernable difference between the subreddits.\n",
    "\n",
    "> - **Best Hyperparameters**:\n",
    "> - 'cvec__max_df': 0.55,\n",
    "> - 'cvec__max_features': 150000,\n",
    "> - 'cvec__min_df': 3,\n",
    "> - 'cvec__ngram_range': (1, 2),\n",
    "> - 'forest__max_depth': 100,\n",
    "> - 'forest__n_estimators': 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debc1f70",
   "metadata": {},
   "source": [
    "### Model 3 Analysis:\n",
    "> Model 3 used TfidVectorizer and KNeighborsClassifier\n",
    "\n",
    "- Training set accuracy of 80.0%\n",
    "- Testing set accuracy of 69.8%\n",
    "\n",
    "Our data is likely very overfit with such a high train and test accuracy difference, although it is seemingly less overfit than our other 2 models. If we were to only be able to use a single model, this would likely be the choice. Again, 70% is high enough for us to use. This data tells us there is possibly a discernable difference between the subreddits.\n",
    "\n",
    "> - **Best Hyperparameters**:\n",
    "> - 'cvec__max_df': 0.9,\n",
    "> - 'cvec__max_features': 100000,\n",
    "> - 'cvec__min_df': 3,\n",
    "> - 'cvec__ngram_range': (1, 2),\n",
    "> - 'knn__n_neighbors': 4,\n",
    "> - 'knn__p': 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d99f4c",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6568fa5f",
   "metadata": {},
   "source": [
    "All 3 models beating our null model by such a degree signifies that there is a discernable difference between the two subreddits, AskScience and ExplainLikeImFive. These models individually gave us a good inclination towards this conclusion and since they all point to the same conclusion, we are even more sure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
