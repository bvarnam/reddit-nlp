{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1767c978",
   "metadata": {},
   "source": [
    "# Project 3: Reddit Post Sorting\n",
    "\n",
    "- **ExplainLikeImFive (ELI5)** - Explain Like I'm Five is the best forum and archive on the internet for layperson-friendly explanations. Don't Panic!\n",
    "- **AskScience** - Ask a science question, get a science answer.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "We will be analyzing a random collection of posts from two subReddits, **ExplainLikeImFive** and **AskScience**, in order to build a model to predict if an individual posts belong to ELI5 or AskScience; we will be analyzing the Title and Body of the Post.\n",
    "\n",
    "**What am I hoping to achieve with this?**\n",
    "> If ELI5 is distinguishable from AskScience.\n",
    "\n",
    "**Why?**\n",
    "> To see if a subreddit focused on explaining things in a simple manner is that much different than a subreddit that wants to explain it any way they can."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c78f2e",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "To collect our data we will be utilizing the Requests library. This library allows us to access websites and, in our case for this project, utilize the websites API to control and obtain desired information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3380e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0e2abf",
   "metadata": {},
   "source": [
    "## Testing and Exploring the Pushshift API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55642d5",
   "metadata": {},
   "source": [
    "We will be using the pushshift API wrapper to access Reddit posts, obtained through the following url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd98491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.pushshift.io/reddit/search/submission'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f1a784",
   "metadata": {},
   "source": [
    "Now we identify the subreddits we wish to access and what information we wish to pull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0246422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params1 and params2 completes the url above according to the pushshift API.\n",
    "params1 = {\n",
    "    'subreddit': 'explainlikeimfive',\n",
    "    'size': 100,\n",
    "    'before': 1631249809\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d6746d",
   "metadata": {},
   "source": [
    "We are ready to pull the data from the API, given our parameters. We then check to ensure it was connected successfully via status_code; 200 being successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df95fdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.get(url, params1)\n",
    "res.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1efa25",
   "metadata": {},
   "source": [
    "Our requests.get() gives us a large text document that can be organized into a json format in what appears to be a dictionary of dictionaries. We can format this with the .json() method. Specifically we want the data section of the encompassing dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f940817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = res.json()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f156498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc82da7",
   "metadata": {},
   "source": [
    "We see that we were able to pull the 100 posts, as indicated by our 'size' param. This is also the maximum amount of posts we can pull in a single request.\n",
    "\n",
    "What kind of data does this represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cb42101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['all_awardings', 'allow_live_comments', 'author', 'author_flair_css_class', 'author_flair_richtext', 'author_flair_text', 'author_flair_type', 'author_fullname', 'author_is_blocked', 'author_patreon_flair', 'author_premium', 'awarders', 'can_mod_post', 'contest_mode', 'created_utc', 'domain', 'full_link', 'gildings', 'id', 'is_created_from_ads_ui', 'is_crosspostable', 'is_meta', 'is_original_content', 'is_reddit_media_domain', 'is_robot_indexable', 'is_self', 'is_video', 'link_flair_background_color', 'link_flair_css_class', 'link_flair_richtext', 'link_flair_template_id', 'link_flair_text', 'link_flair_text_color', 'link_flair_type', 'locked', 'media_only', 'no_follow', 'num_comments', 'num_crossposts', 'over_18', 'parent_whitelist_status', 'permalink', 'pinned', 'pwls', 'removed_by_category', 'retrieved_on', 'score', 'selftext', 'send_replies', 'spoiler', 'stickied', 'subreddit', 'subreddit_id', 'subreddit_subscribers', 'subreddit_type', 'suggested_sort', 'thumbnail', 'title', 'total_awards_received', 'treatment_tags', 'upvote_ratio', 'url', 'whitelist_status', 'wls'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fade1b",
   "metadata": {},
   "source": [
    "To make it more readable, we can turn our data into a dataframe. We don't need all of the informational categories from above, so let's pick what we believe would be most useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9011e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plee4p</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>ELI5: How long does it take for defensins on s...</td>\n",
       "      <td>alisensei</td>\n",
       "      <td>1631249765</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1631249765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pled6q</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>ELI5: What is the difference between the words...</td>\n",
       "      <td>Danaaerys</td>\n",
       "      <td>1631249646</td>\n",
       "      <td></td>\n",
       "      <td>1631249646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plebya</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>ELi5: Why can I seemingly breathe out two diff...</td>\n",
       "      <td>KingRexxi</td>\n",
       "      <td>1631249494</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1631249494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ple9hy</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>ELI5: Why is it impossible to get comfortable ...</td>\n",
       "      <td>smore-phine</td>\n",
       "      <td>1631249200</td>\n",
       "      <td>Have to be up in six hours for work but my min...</td>\n",
       "      <td>1631249200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ple8i3</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>ELI5: How are ideas formed?</td>\n",
       "      <td>Mjosaphine</td>\n",
       "      <td>1631249085</td>\n",
       "      <td></td>\n",
       "      <td>1631249085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id          subreddit  \\\n",
       "0  plee4p  explainlikeimfive   \n",
       "1  pled6q  explainlikeimfive   \n",
       "2  plebya  explainlikeimfive   \n",
       "3  ple9hy  explainlikeimfive   \n",
       "4  ple8i3  explainlikeimfive   \n",
       "\n",
       "                                               title       author  \\\n",
       "0  ELI5: How long does it take for defensins on s...    alisensei   \n",
       "1  ELI5: What is the difference between the words...    Danaaerys   \n",
       "2  ELi5: Why can I seemingly breathe out two diff...    KingRexxi   \n",
       "3  ELI5: Why is it impossible to get comfortable ...  smore-phine   \n",
       "4                        ELI5: How are ideas formed?   Mjosaphine   \n",
       "\n",
       "   created_utc                                           selftext  created_utc  \n",
       "0   1631249765                                          [removed]   1631249765  \n",
       "1   1631249646                                                      1631249646  \n",
       "2   1631249494                                          [removed]   1631249494  \n",
       "3   1631249200  Have to be up in six hours for work but my min...   1631249200  \n",
       "4   1631249085                                                      1631249085  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(posts)[['id','subreddit', 'title', 'author', 'created_utc', 'selftext', 'created_utc']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b6edec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>pl6ihz</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>Eli5 How can the skin regenerate but a cut off...</td>\n",
       "      <td>klusterxx</td>\n",
       "      <td>1631221154</td>\n",
       "      <td></td>\n",
       "      <td>1631221154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>pl6e4z</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>ELI5: How do wind turbines work?</td>\n",
       "      <td>urfavefilipina</td>\n",
       "      <td>1631220760</td>\n",
       "      <td>How does each significant part of the turbine ...</td>\n",
       "      <td>1631220760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>pl6cgb</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>ELI5: What is particle horizon?</td>\n",
       "      <td>iahimide</td>\n",
       "      <td>1631220606</td>\n",
       "      <td></td>\n",
       "      <td>1631220606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>pl6ah2</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>ELI5: how do colorblind glasses work?</td>\n",
       "      <td>Jhams3</td>\n",
       "      <td>1631220429</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1631220429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>pl68us</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>ELI5: What is the difference between the dot p...</td>\n",
       "      <td>camthedps</td>\n",
       "      <td>1631220288</td>\n",
       "      <td></td>\n",
       "      <td>1631220288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id          subreddit  \\\n",
       "95  pl6ihz  explainlikeimfive   \n",
       "96  pl6e4z  explainlikeimfive   \n",
       "97  pl6cgb  explainlikeimfive   \n",
       "98  pl6ah2  explainlikeimfive   \n",
       "99  pl68us  explainlikeimfive   \n",
       "\n",
       "                                                title          author  \\\n",
       "95  Eli5 How can the skin regenerate but a cut off...       klusterxx   \n",
       "96                   ELI5: How do wind turbines work?  urfavefilipina   \n",
       "97                    ELI5: What is particle horizon?        iahimide   \n",
       "98              ELI5: how do colorblind glasses work?          Jhams3   \n",
       "99  ELI5: What is the difference between the dot p...       camthedps   \n",
       "\n",
       "    created_utc                                           selftext  \\\n",
       "95   1631221154                                                      \n",
       "96   1631220760  How does each significant part of the turbine ...   \n",
       "97   1631220606                                                      \n",
       "98   1631220429                                          [removed]   \n",
       "99   1631220288                                                      \n",
       "\n",
       "    created_utc  \n",
       "95   1631221154  \n",
       "96   1631220760  \n",
       "97   1631220606  \n",
       "98   1631220429  \n",
       "99   1631220288  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1da81d9",
   "metadata": {},
   "source": [
    "**Note: 'metadata' is a good way to check total posts to see if the subreddit is a feasible choice for the project.**\n",
    "\n",
    "Also, use time.sleep(x) between subsequent pulls in order to get past the max size of 100 per request without getting blocked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e005569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = {\n",
    "    'subreddit': 'explainlikeimfive',\n",
    "    'metadata': 'true'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbc5c34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = requests.get(url, params2)\n",
    "res2.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0844fb6c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'after': None,\n",
       " 'agg_size': 100,\n",
       " 'api_version': '3.0',\n",
       " 'before': None,\n",
       " 'es_query': {'query': {'bool': {'filter': {'bool': {'must': [{'terms': {'subreddit': ['explainlikeimfive']}}],\n",
       "      'should': []}},\n",
       "    'must_not': []}},\n",
       "  'size': 25,\n",
       "  'sort': {'created_utc': 'desc'}},\n",
       " 'execution_time_milliseconds': 56.79,\n",
       " 'index': 'rs',\n",
       " 'metadata': 'true',\n",
       " 'ranges': [],\n",
       " 'results_returned': 25,\n",
       " 'shards': {'failed': 0, 'skipped': 0, 'successful': 20, 'total': 24},\n",
       " 'size': 25,\n",
       " 'sort': 'desc',\n",
       " 'sort_type': 'created_utc',\n",
       " 'subreddit': ['explainlikeimfive'],\n",
       " 'timed_out': False,\n",
       " 'total_results': 1312328}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2.json()['metadata']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59dbf12",
   "metadata": {},
   "source": [
    "**1.3 million posts should be enough. ExplainLikeImFive will be an acceptable choice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4474472",
   "metadata": {},
   "outputs": [],
   "source": [
    "params3 = {\n",
    "    'subreddit': 'askscience',\n",
    "    'metadata': 'true'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bc1be27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3 = requests.get(url, params3)\n",
    "res3.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bd2e184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1112795"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3.json()['metadata']['total_results']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f43310",
   "metadata": {},
   "source": [
    "**1.1 million posts should be enough. AskScience will be an acceptable choice.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53bfea4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Collect Desired Data\n",
    "\n",
    "Now that we have done some exploration on our SubReddits and found what is available to us through Pushshift's API, let's pull enough data to perform an analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2025619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_data(subreddit):\n",
    "    '''\n",
    "    This function will attempt to pull 10,000 posts from the provided subreddit in chunks of 100.\n",
    "    \n",
    "    Parameter 'subreddit' should be a str, referring to the portion of the url that represents the subreddit.\n",
    "    '''\n",
    "    \n",
    "    # Used to initial our dataframe\n",
    "    i=0\n",
    "    big_df = [[]]\n",
    "    \n",
    "    # We will be finding new posts by using the 'before' paramater available to us by pushshift api.\n",
    "    # Initially, we do not want there to be any 'before' parameter.\n",
    "    set_time = 1631249809\n",
    "    \n",
    "    # Keep running until we have 10,000 posts\n",
    "    while len(big_df) < 10_000:\n",
    "    \n",
    "        # The parameters we pass to the pushshift api to pull data. size=100 is the maximum available \n",
    "        #and we only require data from the listed columns in 'fields'\n",
    "        params = {\n",
    "            'subreddit': subreddit,\n",
    "            'size': 100,\n",
    "            'fields': ['id', 'subreddit', 'title', 'author', 'created_utc', 'selftext', 'body'],\n",
    "            'selftext:not': '[removed]',\n",
    "            'title:not': 'AMA Series',\n",
    "            'num_comments': '>5',\n",
    "            'before': set_time\n",
    "        }\n",
    "\n",
    "        # Access the api through our requests library\n",
    "        res = requests.get(url, params)\n",
    "\n",
    "        # Ensure that our connection was successful (=200); if it isnt, exit and tell us the code it got.\n",
    "        if res.status_code != 200:\n",
    "            return print('There as been an error: res.status_code =', res.status_code)\n",
    "\n",
    "        # Continue with our cycling program if status_code == 200\n",
    "        else:\n",
    "            \n",
    "            # Pull in our data into a variable 'posts'\n",
    "            posts = res.json()['data']\n",
    "            \n",
    "            # Find the post that was submitted at the farthest time from present and set it to 'set_time'\n",
    "            set_time = posts[-1]['created_utc']\n",
    "            \n",
    "            # Initialize our dataframe that will be holding all of the posts for this subreddit\n",
    "            # Grab our first 100 posts\n",
    "            if i == 0:\n",
    "                big_df = pd.DataFrame(posts)\n",
    "                \n",
    "                # Change i so this will not be ran again\n",
    "                i = 1\n",
    "                \n",
    "                # Set a pause time so we don't get blocked by Reddit for abusing the API\n",
    "                time.sleep(1)\n",
    "            \n",
    "            # After our first 100 posts, grab each subsequent 100 posts and concat onto our dataframe\n",
    "            else:\n",
    "                df = pd.DataFrame(posts)\n",
    "                big_df = pd.concat([big_df, df])\n",
    "\n",
    "                # Set a pause time so we don't get blocked by Reddit for abusing the API\n",
    "                time.sleep(1)\n",
    "                \n",
    "    return big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e31eaa36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10095\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChrisGnam</td>\n",
       "      <td>1630428742</td>\n",
       "      <td>pf9tvb</td>\n",
       "      <td>So most of my peers (26 y/o and older) don't h...</td>\n",
       "      <td>askscience</td>\n",
       "      <td>Are there physiological or psychological diffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MaoGo</td>\n",
       "      <td>1629571284</td>\n",
       "      <td>p8wued</td>\n",
       "      <td>Neutrinos are neutrally charged particles that...</td>\n",
       "      <td>askscience</td>\n",
       "      <td>How do we know that the neutrinos have spin?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the_protagonist</td>\n",
       "      <td>1629571059</td>\n",
       "      <td>p8ws1c</td>\n",
       "      <td>How does that “memory” work?  \\n\\nThis comes f...</td>\n",
       "      <td>askscience</td>\n",
       "      <td>If white blood cells are constantly dying and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CyKii</td>\n",
       "      <td>1629567841</td>\n",
       "      <td>p8vtoe</td>\n",
       "      <td>Obviously it's best to be careful about these ...</td>\n",
       "      <td>askscience</td>\n",
       "      <td>If mRNA vaccines remain proven safe, is it act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hairycoo</td>\n",
       "      <td>1629566821</td>\n",
       "      <td>p8vinv</td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>Can't we include multiple virus traits rather ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author  created_utc      id  \\\n",
       "0        ChrisGnam   1630428742  pf9tvb   \n",
       "1            MaoGo   1629571284  p8wued   \n",
       "2  the_protagonist   1629571059  p8ws1c   \n",
       "3            CyKii   1629567841  p8vtoe   \n",
       "4         hairycoo   1629566821  p8vinv   \n",
       "\n",
       "                                            selftext   subreddit  \\\n",
       "0  So most of my peers (26 y/o and older) don't h...  askscience   \n",
       "1  Neutrinos are neutrally charged particles that...  askscience   \n",
       "2  How does that “memory” work?  \\n\\nThis comes f...  askscience   \n",
       "3  Obviously it's best to be careful about these ...  askscience   \n",
       "4                                                     askscience   \n",
       "\n",
       "                                               title  \n",
       "0  Are there physiological or psychological diffe...  \n",
       "1       How do we know that the neutrinos have spin?  \n",
       "2  If white blood cells are constantly dying and ...  \n",
       "3  If mRNA vaccines remain proven safe, is it act...  \n",
       "4  Can't we include multiple virus traits rather ...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_df = pull_data('askscience')\n",
    "print(len(ask_df))\n",
    "ask_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a18101a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>j_d0tnet</td>\n",
       "      <td>1631248750</td>\n",
       "      <td>ple5nz</td>\n",
       "      <td>Disclaimer: I did see a previous question touc...</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>ELI5: Seriously, WTF is up with surface area a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ImpossibleZero</td>\n",
       "      <td>1631247022</td>\n",
       "      <td>pldqkn</td>\n",
       "      <td>I have a 30 year VA loan at 3.75% and my prope...</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>ELI5: What does Refinancing a Mortgage Mean an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80sKidCA</td>\n",
       "      <td>1631246964</td>\n",
       "      <td>pldq29</td>\n",
       "      <td></td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>ELI5: Why and how does your body store tension...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chardington</td>\n",
       "      <td>1631244279</td>\n",
       "      <td>pld1sd</td>\n",
       "      <td>I’ve been getting into finance, stonks and cry...</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>ELI5: What exactly is “liquidity”?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DentonJoe</td>\n",
       "      <td>1631244183</td>\n",
       "      <td>pld0wi</td>\n",
       "      <td>Always wondered why it doesn’t make sense to u...</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>Eli5 why are diesel/electric powertrains econo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author  created_utc      id  \\\n",
       "0        j_d0tnet   1631248750  ple5nz   \n",
       "1  ImpossibleZero   1631247022  pldqkn   \n",
       "2        80sKidCA   1631246964  pldq29   \n",
       "3     Chardington   1631244279  pld1sd   \n",
       "4       DentonJoe   1631244183  pld0wi   \n",
       "\n",
       "                                            selftext          subreddit  \\\n",
       "0  Disclaimer: I did see a previous question touc...  explainlikeimfive   \n",
       "1  I have a 30 year VA loan at 3.75% and my prope...  explainlikeimfive   \n",
       "2                                                     explainlikeimfive   \n",
       "3  I’ve been getting into finance, stonks and cry...  explainlikeimfive   \n",
       "4  Always wondered why it doesn’t make sense to u...  explainlikeimfive   \n",
       "\n",
       "                                               title  \n",
       "0  ELI5: Seriously, WTF is up with surface area a...  \n",
       "1  ELI5: What does Refinancing a Mortgage Mean an...  \n",
       "2  ELI5: Why and how does your body store tension...  \n",
       "3                 ELI5: What exactly is “liquidity”?  \n",
       "4  Eli5 why are diesel/electric powertrains econo...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_df = pull_data('explainlikeimfive')\n",
    "print(len(ex_df))\n",
    "ex_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d806c2",
   "metadata": {},
   "source": [
    "### Check unique ID's to ensure we pulled our data correctly using the 'before' parameters.\n",
    "\n",
    "The number of unique IDs should equal the length of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4c70ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(ask_df['id'].unique()) == len(ask_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f455ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(ex_df['id'].unique()) == len(ex_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d19b00",
   "metadata": {},
   "source": [
    "**Make sure we don't have any deleted or removed posts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0610fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_df[ex_df['selftext']!= '[removed]'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc1a89e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10095, 6)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_df[ask_df['selftext']!= '[removed]'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f9fe1e",
   "metadata": {},
   "source": [
    "**Success!**\n",
    "\n",
    "Now let's save these dataframes into csv's to be explored and analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "306823fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_df.to_csv('../data/ask_df.csv', index=False)\n",
    "ex_df.to_csv('../data/ex_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee1c80e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87a2fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d06254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a2df9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da647a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d621fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccf7ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "89385544",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70c9df2",
   "metadata": {},
   "source": [
    "# Comment Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11be4a84",
   "metadata": {},
   "source": [
    "I really wanted this to work but my attempts thus far have been unsuccessful.\n",
    "- Currently stuck connecting to the specific submission via 'parent_id'. There is a successful connection, but no comments are pulled. Either the 'parent_id' is wrong, there is an issue on the backend, or there is an issue with the res.json().\n",
    " - Successful pulls top comments in the subreddit when 'parent_id' is not given.\n",
    " - When 'parent_id' is given, gives empty list for posts and empty dataset for temp.\n",
    "\n",
    "---\n",
    "\n",
    "Top comments will not be included in the model.\n",
    "- It would be very helpful in our classification model as the top comment by score is usually the 'accepted answer' and is in a specific vernacular depending on which subreddit we are in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a888c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(df, subreddit):\n",
    "        \n",
    "    text_url = 'https://api.pushshift.io//reddit/search/comment'\n",
    "    new_df = df.copy()\n",
    "    new_df['top_comment'] = ['']*len(df)\n",
    "    \n",
    "    for j, Id in enumerate(df['id']):\n",
    "        \n",
    "                            \n",
    "        params = {\n",
    "        'subreddit': subreddit,\n",
    "        'size': 1,\n",
    "        'sort_type': 'score',\n",
    "        'parent_id': 't1' + new_df.iloc[1]['id'],\n",
    "        }\n",
    "\n",
    "        # Access the api through our requests library\n",
    "        res = requests.get(text_url, params)\n",
    "\n",
    "        # Ensure that our connection was successful (=200); if it isnt, exit and tell us the code it got.\n",
    "        if res.status_code != 200:\n",
    "            return print('There as been an error: res.status_code =', res.status_code)\n",
    "\n",
    "        # Continue with our cycling program if status_code == 200\n",
    "        else:\n",
    "\n",
    "            # Pull in our data into a variable 'posts'\n",
    "            posts = res.json()['data']\n",
    "            temp = pd.DataFrame(posts)         \n",
    "            \n",
    "            if posts != []:\n",
    "                new_df.iloc[j]['top_comment'] = temp['body'][0]\n",
    "            \n",
    "            # Set a pause time so we don't get blocked by Reddit for abusing the API\n",
    "            time.sleep(1)\n",
    "\n",
    "          \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "229274ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-481b585fe701>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_comments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'explainlikeimfive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-110-c99964e06802>\u001b[0m in \u001b[0;36mget_comments\u001b[1;34m(df, subreddit)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;31m# Set a pause time so we don't get blocked by Reddit for abusing the API\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_comments(ex_df, 'explainlikeimfive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9fd4c6c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author                                              mintee-fresh\n",
       "created_utc                                           1631239520\n",
       "id                                                        plbsi4\n",
       "selftext       I don't really understand how seeding works wh...\n",
       "subreddit                                      explainlikeimfive\n",
       "title                    ELI5: How does seeding work in weather?\n",
       "Name: 12, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_df.iloc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e451f36",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'body'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'body'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-a839e9da88f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_ask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_comments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mask_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'explainlikeimfive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnew_ask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-58-cbd56921edf2>\u001b[0m in \u001b[0;36mget_comments\u001b[1;34m(df, subreddit)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mnew_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'top_comment'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'body'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3453\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3454\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3455\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'body'"
     ]
    }
   ],
   "source": [
    "new_ask = get_comments(ask_df, 'explainlikeimfive')\n",
    "new_ask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a572fefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ex = get_comments(ex_df, 'askscience')\n",
    "new_ex.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
